clouddomain: ci.vexxhost.ca
manila_enabled: true
ceph_devices:
  - /dev/sdb
ephemeral_storage_devices:
  - /dev/sdc
  - /dev/sdd
rhsm_enabled: true
rhsm_release: 8.4
rhsm_container_tools_version: 3.0
rhsm_repos:
  - advanced-virt-for-rhel-8-x86_64-rpms
  - ansible-2.9-for-rhel-8-x86_64-rpms
  - fast-datapath-for-rhel-8-x86_64-rpms
  - openstack-16.2-for-rhel-8-x86_64-rpms
  - rhceph-4-tools-for-rhel-8-x86_64-rpms
  - rhel-8-for-x86_64-appstream-eus-rpms
  - rhel-8-for-x86_64-baseos-eus-rpms
  - rhel-8-for-x86_64-highavailability-eus-rpms
virt_release: av
cip_config:
  - set:
      ceph_alertmanager_image: ose-prometheus-alertmanager
      ceph_alertmanager_namespace: registry.redhat.io/openshift4
      ceph_alertmanager_tag: 4.1
      ceph_grafana_image: rhceph-4-dashboard-rhel8
      ceph_grafana_namespace: registry.redhat.io/rhceph
      ceph_grafana_tag: 4
      ceph_image: rhceph-4-rhel8
      ceph_namespace: registry.redhat.io/rhceph
      ceph_node_exporter_image: ose-prometheus-node-exporter
      ceph_node_exporter_namespace: registry.redhat.io/openshift4
      ceph_node_exporter_tag: v4.1
      ceph_prometheus_image: ose-prometheus
      ceph_prometheus_namespace: registry.redhat.io/openshift4
      ceph_prometheus_tag: 4.1
      ceph_tag: latest
      name_prefix: openstack-
      name_suffix: ''
      namespace: registry.redhat.io/rhosp-rhel8
      neutron_driver: ovn
      rhel_containers: false
      tag: '16.2'
    tag_from_label: '{version}-{release}'
# OpenStack API runnings under WSGI have a common function to calculate the number of workers:
# The value for os_workers is max between '(<# processors> / 2)' and '2' with
# a cap of 12.
# https://opendev.org/openstack/puppet-openstacklib/src/commit/495701901eabb24d28f2a2276275e1c1537133c1/lib/facter/os_workers.rb#L37-L38
# On vexxhost machines, we have 96 cores, so each API can create up to 12 workers.
# This has been problematic for us when deploying OpenShift with Kuryr which
# consumes a lot of load balancers and Octavia is using more than half of the RAM available on the host
# so we decided to reduce the number of workers to reduce the amount of RAM that will be consumed.
standalone_extra_config:
  octavia::wsgi::apache:workers: 4
dpdk_interface: enp161s0f1
kernel_args: "default_hugepagesz=1GB hugepagesz=1G hugepages=128 iommu=pt amd_iommu=on isolcpus=6-95"
tuned_isolated_cores: "6-95"
extra_heat_params:
  NovaComputeCpuDedicatedSet: ['8-95']
  NovaReservedHostMemory: 4096
  NovaComputeCpuSharedSet: [0,1,2,3,4,5]
  OvsDpdkSocketMemory: "2048,2048"
  OvsPmdCoreList: "6,7" 
